{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8d30074",
   "metadata": {},
   "source": [
    "# Fetching Data Using The Kaggle API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71463d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from zipfile import ZipFile\n",
    "\n",
    "api = KaggleApi() \n",
    "api.authenticate()\n",
    "\n",
    "def fetch_data():\n",
    "    api.competition_download_files('digit-recognizer')\n",
    "    zf = ZipFile('digit-recognizer.zip')\n",
    "    zf.extractall('/Users/soosan/Documents/ML/MNIST Digit Classifier/Data/')\n",
    "    zf.close()\n",
    "    \n",
    "fetch_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb9318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Uses the Kaggle API to download the datasets, unzip them and store them in the local machine'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6324d349",
   "metadata": {},
   "source": [
    "# Loading Training And Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85aa551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_data():\n",
    "    csv_train_path = os.path.join('/Users/soosan/Documents/ML/MNIST Digit Classifier/Data', 'train.csv')\n",
    "    csv_test_path = os.path.join('/Users/soosan/Documents/ML/MNIST Digit Classifier/Data', 'test.csv')\n",
    "    return pd.read_csv(csv_train_path), pd.read_csv(csv_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f9aacd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stores the path of the csv file downloaded and returns it in the form of a DataFrame'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Stores the path of the csv file downloaded and returns it in the form of a DataFrame'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8097a905",
   "metadata": {},
   "source": [
    "# Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c749cfae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0      1       0       0       0       0       0       0       0       0   \n",
      "1      0       0       0       0       0       0       0       0       0   \n",
      "2      1       0       0       0       0       0       0       0       0   \n",
      "3      4       0       0       0       0       0       0       0       0   \n",
      "4      0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
      "0       0  ...         0         0         0         0         0         0   \n",
      "1       0  ...         0         0         0         0         0         0   \n",
      "2       0  ...         0         0         0         0         0         0   \n",
      "3       0  ...         0         0         0         0         0         0   \n",
      "4       0  ...         0         0         0         0         0         0   \n",
      "\n",
      "   pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0  \n",
      "1         0         0         0         0  \n",
      "2         0         0         0         0  \n",
      "3         0         0         0         0  \n",
      "4         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns] \n",
      "\n",
      "(42000, 785) \n",
      "\n",
      "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
      "0       0       0       0       0       0       0       0       0       0   \n",
      "1       0       0       0       0       0       0       0       0       0   \n",
      "2       0       0       0       0       0       0       0       0       0   \n",
      "3       0       0       0       0       0       0       0       0       0   \n",
      "4       0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
      "0       0  ...         0         0         0         0         0         0   \n",
      "1       0  ...         0         0         0         0         0         0   \n",
      "2       0  ...         0         0         0         0         0         0   \n",
      "3       0  ...         0         0         0         0         0         0   \n",
      "4       0  ...         0         0         0         0         0         0   \n",
      "\n",
      "   pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0  \n",
      "1         0         0         0         0  \n",
      "2         0         0         0         0  \n",
      "3         0         0         0         0  \n",
      "4         0         0         0         0  \n",
      "\n",
      "[5 rows x 784 columns] \n",
      "\n",
      "(28000, 784) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = load_data()\n",
    "\n",
    "print(train_data.head(), '\\n')\n",
    "print(train_data.shape, '\\n')\n",
    "\n",
    "print(test_data.head(), '\\n')\n",
    "print(test_data.shape, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e7b4bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We can see that there are 42k images. Each image can be represented by a 2D array of 28 x 28 pixels. This 2D array\\n   when flattened into a single dimension has 1 x 784 pixels. There's a label column that signifies the digit drawn by\\n   the user. There are 10 classes as there are 10 digits we have to identify.\\n   \\n   The test data has 28000 images with 784 columns signifying the pixels.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''We can see that there are 42k images. Each image can be represented by a 2D array of 28 x 28 pixels. This 2D array\n",
    "   when flattened into a single dimension has 1 x 784 pixels. There's a label column that signifies the digit drawn by\n",
    "   the user. There are 10 classes as there are 10 digits we have to identify.\n",
    "   \n",
    "   The test data has 28000 images with 784 columns signifying the pixels.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bd0761",
   "metadata": {},
   "source": [
    "# Data Manipulation And Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e6b9b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(train, test):\n",
    "    train = train/255\n",
    "    test = test/255\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1959d774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The pixel values for the images range from 0(black) to 255(white). Since MLPs(Multi Layer Perceptons) are sensitive\\n   to feature scaling, we will divide the train and test set with 255, so as to keep the values between 0 and 1.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''The pixel values for the images range from 0(black) to 255(white). Since MLPs(Multi Layer Perceptons) are sensitive\n",
    "   to feature scaling, we will divide the train and test set with 255, so as to keep the values between 0 and 1.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46021817",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "170aa02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MLPs are trained using Backpropagation, which is a supervised learning algorithm using gradient descent which \\n   calculates the gradient of the loss fucntion with respect to the weight spaces of a feedforward neural network.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''MLPs are trained using Backpropagation, which is a supervised learning algorithm using gradient descent which \n",
    "   calculates the gradient of the loss fucntion with respect to the weight spaces of a feedforward neural network.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a95a1dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56669235",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.iloc[:, 1:]\n",
    "y = train_data.loc[:,'label'] #Splitting the training data into two dataframes cmprising features and labels\n",
    "\n",
    "X, test_data = scale(X, test_data) #Scaling the DataFrames as MLP is sensitive to feature scaling\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2) #Splitting the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2212d8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_Classifier = MLPClassifier(max_iter = 3000, random_state = 1, learning_rate_init = 0.1) #Initializes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad2eaae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Defines Parameter Space for hyperparameter tuning using GridSearch CV'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameter_space = {'hidden_layer_sizes': [(50,50,50), (50,20,10), (397,)],\n",
    "                        'activation': ['tanh', 'relu', 'logistic'],\n",
    "                        'solver': ['sgd', 'adam'],\n",
    "                        'alpha': [1e-4, 0.05],\n",
    "                        'learning_rate': ['constant','adaptive'],\n",
    "                        }\n",
    "\n",
    "'''Defines Parameter Space for hyperparameter tuning using GridSearch CV'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d01bbcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=MLPClassifier(learning_rate_init=0.1, max_iter=3000,\n",
       "                                     random_state=1),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'activation': ['tanh', 'relu', 'logistic'],\n",
       "                         'alpha': [0.0001, 0.05],\n",
       "                         'hidden_layer_sizes': [(50, 50, 50), (50, 20, 10),\n",
       "                                                (397,)],\n",
       "                         'learning_rate': ['constant', 'adaptive'],\n",
       "                         'solver': ['sgd', 'adam']})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OP_NN_Classifier = GridSearchCV(NN_Classifier, hyperparameter_space, n_jobs=-1, cv=3) #Creates a tuned classifier\n",
    "OP_NN_Classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48820e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Score:  1.0\n",
      "Testing Set Score:  0.9798809523809524\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set Score: \", OP_NN_Classifier.score(X_train, y_train))\n",
    "print(\"Testing Set Score: \", OP_NN_Classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9099b94",
   "metadata": {},
   "source": [
    "# Predicting On Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b93d6cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = OP_NN_Classifier.predict(test_data)\n",
    "df = pd.DataFrame(predictions)\n",
    "df.index = range(1, len(df) + 1)\n",
    "df.to_csv('/Users/soosan/Documents/ML/MNIST Digit Classifier/Data/predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1da7fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
